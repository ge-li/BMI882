# Bootstrap in Regression

### [Freedman and Peters (1984)](https://www.jstor.org/stable/2288341)

##### Title: Bootstrapping a Regression Equation: Some Empirical Results 

##### Author: DAVID A. FREEDMAN and STEPHEN C. PETERS

In this paper, the authors described a resampling technique, i.e., bootstrapping on regression residuals, to estimate standard errors. It somewhat resembles the semiparametric model where it assumes the validity of some model, i.g., a dynamic linear model was considered here. And it assumes no specific underlying error distribution but instead uses the fitted residual to simulate new samples. The estimation of the parameters will be done on new samples iteratively. The standard errors and confidence intervals can then generated by using the bootstrapped estimates. The authors used an example of an econometric equation describing the demand for energy by industry as an example. The empirical results showed that the conventional asymptotic formulas for estimating standard errors are too optimistic by comparing the bootstrapping standard deviation (SD) and RMS(?) Nominal SE (the squared root of the sum of the squares of the standard error estimated using nominal formula). However, the biases of the bootstrapping estimator are also significant in this setting. The author then gave some mathematical explanation on why nominal SE performs bad comparing to bootstrapping SD in a simpler setting.

I used only to know bootstrapping by simply resampling data points with replacement. But it turns out that we can resample residuals if we believe some modelâ€”this is what I found most interesting. I also found this short article useful ([Which Bootstrap When?](https://www.stat.cmu.edu/~cshalizi/uADA/13/lectures/which-bootstrap-when.pdf)). 

Question(s):

* Is bootstrapping the magical method for all scenarios? When shouldn't we use bootstrapping?

