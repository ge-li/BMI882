# False Discovery Rate

### [Benjamini and Hochberg (1995)](https://doi.org/10.1111/j.2517-6161.1995.tb02031.x)

##### Title: Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing

##### Author: Yoav Benjamini, Yosef Hochberg

In this paper, the authors proposed a new approach to multiple testing (or multiple-comparison procedures MCPs). Instead of controlling the familywise error rate (FWER), they conceive the idea of controlling the false discovery rate (FDR) to accommodate the use of different test statistics, the purpose of varying research settings, and to gain statistical power. The definition of FDR is the expected value of the proportion of the rejected null hypothesis which are erroneously rejected. In contrast, FWER is defined as the probability to have even one falsely rejected the null hypothesis. The two are equivalent when all null hypotheses are true; otherwise, FDR is smaller. FDR provides some leniency. Thus, potential statistical power gain. The authors also proposed a simple procedure to control the FRD using p-values. And demonstrate the statistical power gain using a simulation study and real examples. 

* I think the Table 1 is really helpful and clear on how to model the multiple testing problem using random variables. 
* The proposed procedure seems easy enough to implement. I'm not so sure that I understand the proof of the lemma. Is there any straightforward intuition behind it?
* I don't quite follow the explanation in the final part of the simulation when the authors use Fig. 1 to answer the question raised by a referee on why E(V/m_0) is controlled by the FRD controlling method. 

Questions:

* How to better understand the proposed procedure and explain the intuition behind it?
* Does the proposed procedure achieve the highest power across all possible procedures to control FDR?
* What are the disadvantages of using FDR? Are there scenarios where you don't hope to have any false discovery?

