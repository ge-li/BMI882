# fMRI p-values

### [Eklund et al. (2016)](https://doi.org/10.1073/pnas.1602413113)

##### Title: Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates

##### Author: Anders Eklund, Thomas E. Nichols, and Hans Knutsson

In this paper, the authors validate several widely used statistical methods and software using real functional magnetic resonance imaging (fMRI) data. For a nominal familywise error rate of 5%, the parametric statistical methods (SPM, FLAME1, FSL, OLS, 3dttest, 3dMEMA) are shown to be conservative for voxelwise inference, meaning the empirical type I error, or false-positive rate are smaller than expected; and invalid for clusterwise inference, meaning hugely inflated type I error, or false-positive rate. By examining a range of assumptions used by parametric models, e.g., theoretical null distribution, the spatial autocorrelation function of noise, and whether the false clusters appear randomly in the brain, etc. Their results suggest that the principal cause of the invalid cluster inferences is spatial autocorrelation functions that do not follow the assumed Gaussian shape. By comparison, the nonparametric permutation test is found to have familywise error (FWE) within the expected confidence interval for voxelwise as well as clusterwise inference, it can still be invalid or highly skewed in the one-sample test. The authors shed questions upon the validity of many fMRI studies and urge careful use of statistical methods and improved data sharing and reproducibility in fMRI studies.

* It's not surprising that many fMRI studies will have inflated false-positive rates. The problem is applying statistical methods without examing the assumptions. The fault is not statistical methods developed out of good intentions. It's the misuse and misinterpretation of them. And some studies didn't even use them! For example, "yet some 40% of a sample of 241 recent fMRI papers did not report correcting for multiple comparisons". 

* "Due to lamentable archiving and data-sharing practices, it is unlikely that problematic analyses can be redone". Again, improving data sharing and reproducibility is urgent and important in almost all fields of science!

Questions:

* Is there any similar situation happening in your familiar field of studies?
* What can we do to avoid misuse and misinterpretation of statistical methods?